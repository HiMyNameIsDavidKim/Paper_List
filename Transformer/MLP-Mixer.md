# MLP-Mixer: An all-MLP Architecture for Vision
* TOLSTIKHIN, Ilya O., et al. Advances in neural information processing systems, 2021, 34: 24261-24272.
* NIPS 2021
<br><br>

## [`논문 요약`]

### [저자의 의도]
* convolution layer와 attention layer가 반드시 필요한건 아니다.
* 오직 MLP만 사용하는 MLP-Mixer architecture 제시.
<br><br>

### [기존 문제점]
* CNN과 ViT의 architecture가 너무 복잡하다.
<br><br>

### [해결 아이디어]
* convolution 이나 self-attention 레이어를 사용하지 말자.
* 오직 MLP로 이루어진 architecture 고안.
* MLP 
<br><br>

### [추가로 볼 레퍼런스]
* 
<br><br>

### [내 아이디어]
* 
<br><br>



## [`메모`]

### [배경 지식]
* 
<br><br>


