# FSDL

## `[딥러닝 테스트 방법]`
* [`Lecture 3: Troubleshooting & Testing`](https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/)
* [`Lab 5: Troubleshooting & Testing`](https://fullstackdeeplearning.com/course/2022/lab-5-troubleshooting-and-testing/)
<br><br>

### [기존 SW 개발에서 테스트]
* 테스트는 버그를 잡는 것을 넘어 빠르고 안전하게 SW를 출시하도록 돕는다.
* 테스트는 '버그가 있을 때 이해되는 방식으로 실패하도록 설계된 코드' 이다.
* 테스트가 모든 버그를 잡아주지는 않으며 100% 보장을 목표로 할 필요는 없다.
* 테스트 스위트 = 분류기
    * '커밋에 버그가 있는가?' 라는 분류 문제에 대해 예측하는 것으로 이해하자.
    * 이 방법이 테스트 스위트를 설계하는 새로운 관점을 제시해 준다.
    * 버그 탐지만 신경쓰는 것이 아니라 오경보를 줄이는 것도 중요하다.
    * 오경보는 테스트는 실패했으나 실제로는 코드에 문제가 없는 것이다.
<br><br>

### [테스팅 도구]
* Pytest
    * 파이썬 코드 테스트를 위한 표준 도구이다.
    * 파이써닉하며 강력한 마크, 리소스 공유, 테스트 기능을 제공한다.
* Doctest
    * 독스트링 내의 코드를 테스트하는 파이썬 내장 도구이다.
    * 독스트링은 함수나 클래스의 문서화 문자열이다.
    * 독스트링과 코드의 동기화를 유지하여 신뢰도를 높인다.
* Notebook test
    * 주피터 노트북은 테스트하기 어려운 편이다.
    * 임시 방편으로 노트북의 코드 마지막에 assert와 nbformat을 추가할 수 있다.
<br><br>

### [린팅 도구]
* 린팅은 코드의 스타일, 품질, 깔끔함 (cleanliness)을 검사하는 도구이다.
* 코드 리뷰에서 스타일 논쟁을 줄이고 VCS의 유용성을 높일 수 있다.
* 커뮤니티의 표준 스타일을 채택하면 오픈 소스 기여를 쉽게 받을 수 있다.
* Black
    * 파이썬 코드의 일관된 서식 (ex. 공백)을 위한 표준 도구이다.
    * 스타일 편차를 감지하고 자동으로 수정하는 기능을 제공한다.
* Flake8
    * 자동화할 수 없는 스타일 (ex. 독스트링 누락, 타입 힌트)을 검사하는 도구이다.
    * 수많은 플러그인을 통해 기능을 확장할 수 있다.
    * 보안 문제와 일반 버그까지 확인할 수 있다.
* ShellCheck
    * 쉘 스크립트의 오류 및 문제점을 감지하고 설명을 제공한다.
    * 매우 빠르고 유용하여 컨텍스트 전환 없이 무제를 해결할 수 있다.
* 스타일 규칙을 지나치게 엄격하게 적용하면 역효과가 날 수 있다.
* 엔지니어들이 불필요한 스타일 문제에 집중하게 될 수 있다.
* 따라서, 최소한의 스타일 규칙만 적용하고 규칙을 점진적으로 확대하는 것이 좋다.
<br><br>

### [테스트와 린팅의 자동화]
* 테스트와 린팅 관행을 최대한 활용하려면 자동화를 도입해야한다.
* 자동화의 장점
    * VCS와 연결하여 에러 재현 및 이해 마찰을 줄여준다.
    * 개발 환경 외부에서 병렬로 실행해 다른 작업에 집중할 수 있다.
    * 수동으로 명령어를 기억하고 입력하지 않아도 된다.
    * 수동보다 문제를 더 빨리 감지할 수 있다.
    * 작은 팀일 경우 생산성을 크게 향상시켜준다.
    * 자동화 스크립트 자체가 프로세스에 대한 문서화 역할을 한다.
* GitHub Actions
    * FSDL에서 추천하는 자동화 도구이다.
    * 버전 관리 시스템과 직접 연동된다.
    * 강력하고 유연하며, 무료 등급에 관대하다.
    * 뛰어난 성능과 쉬운 사용법을 제공한다.
    * 오픈 소스 커뮤니티에 다양한 액션이 존재한다.
    * 파이토치와 같은 대규모 오픈소스 프로젝트에서도 사용된다.
<br><br>

### [딥러닝에서 테스트의 특수성]
* 딥러닝 테스트는 기존 SW 테스트보다 본질적으로 더 어렵다.
* 기존 SW는 소스 코드를 컴파일하여 프로그램을 만든다.
* 반면에 딥러닝은 데이터를 학습하여 모델을 만든다.
* 딥러닝 데이터는 SW 소스코드보다 무겁고 이해하기 어렵다.
* 딥러닝 학습은 SW 컴파일보다 복잡하고 정의가 모호하며 성숙도가 낮다.
* 딥러닝 모델은 기존 SW 프로그램보다 디버깅 및 검사 도구가 부족하다.
* 이런 이유로 딥러닝은 'SW 테스팅 업계의 다크소울'에 비유되기도 한다.
* 딥러닝 테스트의 종류는 다음과 같다.
    * 데이터 테스트, 학습 코드 테스트, 모델 테스트, 모델 행동 테스트
* 스모크 테스트
    * 딥러닝 테스트는 스모크 테스트에 집중하는 것이 효과적이다.
    * 스모크 테스트는 시스템에 불이 났을 때 연기가 나며 알려주는 것이다.
    * 다시 말해, 심각한 문제가 나면 즉시 알림을 받고 대응할 수 있다.
    * 이는 훨씬 구현하기 쉽고 80%의 가치를 제공하는 20%의 테스트에 해당한다.
<br><br>

### [데이터 테스트]
* 데이터 테스트는 expectation test를 진행한다.
* 데이터의 기본적인 속성을 확인하는 테스트이다.
* 컬럼에 Null이 있는지, 완료일이 시작일보다 늦은지와 같은 기대를 명시한다.
* 소수의 속성부터 시작해서 점진적으로 확장한다.
* 알람을 울릴 가치가 있는 것만 테스트한다.
* 너무 엄격한 기대를 하지 않도록 유의하며 범위를 완화한다.
* Great Expectations
    * FSDL에서 데이터 테스트에 추천하는 도구이다.
    * 데이터셋에 대한 문서와 품질 보고서를 자동으로 생성할 수 있다.
    * 기대 테스트를 위해 내장된 로깅 및 학습 기능을 제공한다.
* 데이터 어노테이션 설정
    * 모델 개발자가 주기적으로 직접 데이터를 어노테이션하는 것이 이상적이다.
    * 내부 어노테이션 팀과 모델 개발자 간의 정기적인 회의가 필요하다.
    * 프로젝트 초기에만 이라도 모델 개발자가 데이터를 어노테이션하는 것도 좋다.
<br><br>

### [학습 코드 테스트]
* 학습 코드 테스트는 memorization test를 진행한다.
* 모델이 아주 작은 데이터셋을 암기할 수 있는지 확인하는 테스트이다.
* 신경망은 기본적으로 데이터 암기에 매우 능숙하다.
* 따라서 작은 데이터셋도 암기하지 못한다면 심각한 문제가 있는 것이다.
* 파이토치 라이트닝의 overfit_batch를 사용하면 쉽게 구현할 수 있다.
* 실패 시 확인해야할 포인트
    * 그라디언트 계산에 오류가 있는지 확인한다.
    * 수치를 계산하는 함수에 문제가 있는지 확인한다.
    * 레이블이 뒤섞여 제대로 학습되지 않는지 확인한다.
* memorization test 외 속도 관련 2가지 테스트 추가 진행
    * 추론 시간이 오래걸리지 않는지 확인한다.
    * 특정 loss 기준까지 도달하는데 시간이 너무 오래 걸리는지 확인한다.
<br><br>

### [모델 테스트]
* 모델 테스트는 regression test를 진행한다.
* 모델은 본질적으로 함수이므로 입력에 대한 예상 출력을 테스트할 수 있다.
* 생산 환경에서 관찰된 버그를 `테스트 스위트`로 추가해 재발을 방지하는 것이다.
* 분류처럼 출력이 간단한 작업에서는 아주 쉽게 테스트 할 수 있다.
* 분류가 아니더라도 다음과 같은 테스트를 진행할 수 있다.
    * 데이터셋에서 손실이 높은 데이터를 찾아 처리할 수 있는지 확인한다.
    * 유사한 유형의 실패를 분석하고 모델이 처리할 수 있는지 확인한다.
<br><br>

### [모델 행동 테스트]
* 모델이 성숙해지고 행동에 대한 이해가 깊어지면 행동 테스트를 진행한다.
* 기존 보다 더 많은 모델 기능을 테스트 한다.
* 모델을 판단하기 위한 복잡한 체크리스트를 생성해 테스트한다.
<br><br>

### [ML test score]
* [`ML test score`](https://research.google/pubs/the-ml-test-score-a-rubric-for-ml-production-readiness-and-technical-debt-reduction/)
* 구글 리서치에서 개발된 딥러닝 모델의 품질을 평가하는 도구이다.
* ML 프로젝트의 테스트 품질을 조직화하기 위해 만든 엄격한 기준이다.
* 데이터, 모델, 인프라, 모니터링 에 대한 여러가지 항목을 검사한다.
* 왜 검사하는지 어떻게 검사하는지 자세하게 작성되어 있다.
<br><br>



## `[딥러닝 이슈 해결 방법]`
* [`Lecture 3: Troubleshooting & Testing`](https://fullstackdeeplearning.com/course/2022/lecture-3-troubleshooting-and-testing/)
* [`Lab 5: Troubleshooting & Testing`](https://fullstackdeeplearning.com/course/2022/lab-5-troubleshooting-and-testing/)
<br><br>

### [모델 트러블슈팅]
* 모델 트러블슈팅은 딥러닝 파이프라인에서 가장 어려운 부분 중 하나이다.
* 트러블슈팅을 위해 3단계 접근법을 따르는 것이 좋다.
    1. 모델이 실행되도록 만든다. (Make it run)
    2. 모델을 빠르게 만든다. (Make it fast)
    3. 모델을 올바르게 만든다. (Make it right)
<br><br>

### [Make it run]
* 모델이 실행되도록 만드는 단계이다.
* 이 단계는 비교적 쉬운 단계에 속한다.
* 딥러닝의 버그 중 아주 일부만 모델을 멈추게 하기 때문이다.
* Shape 오류
    * 텐서의 shape가 연산에 필요한 shape와 일치하지 않을 때 발생한다.
    * 파이토치 코드를 작성할 때 예상 shape를 주석으로 달고 지속 확인한다.
* 메모리 부족 (Out of Memory, OOM)
    * GPU의 용량보다 너무 큰 텐서를 할당하려고 할 때 발생한다.
    * 배치 크기를 줄이는 것이 가장 쉬우나 학습이 불안정해질 수 있다.
    * 파이토치 라이트닝의 auto_scale_batch_size를 활용한다.
    * float의 정밀도를 낮추거나 모델을 더 작게 만들 수 있다.
    * 분산학습과 같은 기법을 활용하여 메모리 사용량을 줄일 수 있다.
* Numerical 오류
    * 텐서에 NaN 또는 무한대 값이 입력될 때 발생한다.
    * 그라디언트가 폭발하거나 수렴하여 학습이 멈춰버리는 경우이다.
    * 파이토치 라이트닝의 gradient norm 추적 및 로깅 도구를 활용한다.
    * Batch Norm, Layer Norm 과 같은 정규화 기법을 활용한다.
<br><br>

### [Make it fast]
* 모델이 실행되고 gradient가 잘 계산된다면, 이제 빠르게 만드는 단계이다.
* 딥러닝 학습 코드의 속도는 종종 직관과는 다르게 작동한다.
* 속도 병목 현상의 비직관성
    * 트랜스포머 블럭에서 어텐션보다 MLP가 오히려 더 느린 경우가 많다.
    * optimizer state가 모델이나 데이터보다 더 많은 메모리를 사용한다.
    * 데이터 로딩과 같은 사소해 보이는 것들이 전체 속도를 크게 저하시킬 수 있다.
* 속도 병목 현상을 찾는 방법
    * 프로파일링 도구를 사용하여 속도 병목 현상을 찾아낸다.
    * 파이토치에서는 `torch.profiler`를 사용하여 프로파일링할 수 있다.
    * 종종 코드의 작은 변경으로 속도를 높이는 `로우 행잉 프루트`를 찾을 수 있다.
<br><br>

### [Make it right]
* 모델이 올바르게 작동하도록 만드는 단계이다.
* 기존 SW 개발은 run -> right -> fast 순으로 진행된다.
* 딥러닝은 run -> fast -> right 순으로 right가 가장 마지막 단계이다.
* 마지막에 right를 하는 이유
    * 딥러닝 모델은 항상 틀린다.
    * 딥러닝 모델은 완벽하지 않고 손실이 0을 도달할 수 없다.
    * 모델의 정확도 문제를 스케일링으로 해결할 수 있는 경우가 많다.
    * 오버피팅에서는 데이터 스케일 업이 해결 방법 중 하나이다.
    * 언더피팅에서는 모델 스케일 업이 해결 방법 중 하나이다.
    * 실제 환경에서 성능이 낮다면 데이터와 모델을 모두 스케일 업해야 한다.
* 스케일링 법칙
    * scaling laws는 OpenAI와 같은 기업에서 입증한 연구 결과이다.
    * 컴퓨팅 예산, 데이터셋 크기, 파라미터 수를 늘리면 성능이 향상된다.
    * 물론 스케일링에는 막대한 비용 문제라는 단점이 있다.
    * 비용 문제를 감당할 수 없다면 사전학습된 모델을 활용하는 것이 좋다.
* 가장 좋은 접근법은 huggingface 혹은 최신 논문의 이론과 가장 가깝게 유지하는 것이다.
* 수많은 연구자들이 효과적인 기술을 기반으로 점진적으로 발전시켜온 결과물이기 때문이다.
<br><br>

### [CPU와 GPU]
* W&B의 트레이스 뷰어로 CPU와 GPU의 활동을 시각적으로 확인할 수 있다.
* 딥러닝 코드의 특징은 GPU에 의해 가속된다.
* 여기서 가장 중요한 특징은 CPU와 GPU 간의 비동기적 활동이다.
* CPU가 배치 정보를 GPU로 옮기는 동안 메인 파이썬 프로세스는 연산을 계속 진행한다.
* 데이터가 GPU에 있을 때 어떤 작업을 진행할지 파악하고 결정한다.
* Mem copy: GPU에서 가장 먼저하는 것으로 CPU에서 GPU로 메모리 복사하는 것이다.
* Kernel launch: C로 작성된 커널이 GPU를 빠르게 실행시킨다.
* CPU-GPU 동기화: CPU가 GPU의 작업이 완료될 때까지 기다리는 것으로 CPU가 멈춘다.
* GPU의 활용률을 체크하고 90%가 넘는다면 GPU가 잘 활용되고 있는 것이다.
<br><br>

### [속도 최적화를 위한 추가 팁]
* 속도 문제를 해결하고 더 높은 GPU 활용률을 달성하기 위한 몇가지 팁을 제안한다.
* forward pass에 집중
    * forward pass에만 집중하는 것이 가장 큰 속도 향상을 가져온다.
    * backward pass는 forward pass에 종속된다.
    * forward pass가 느리면 backward pass도 느려진다.
    * forward pass는 예측하기 더 쉽고 제어하기가 더 용이하다.
* 최대한 큰 배치 사이즈 사용
    * GPU RAM이 가용하는 최대한 큰 배치 사이즈를 사용하는 것이 좋다.
    * 파이썬에서 커널을 실행하는 것보다 GPU가 실행하는 것이 훨씬 빠르다.
* 데이터 로딩 최적화
    * 데이터 로더의 num_workers를 늘려서 데이터 로딩을 병렬화한다.
    * num_workers를 0으로 설정하면 매우 낮은 GPU 활용률을 초래한다.
    * GPU가 데이터를 기다리는 시간이 길어져 유휴 상태가 길어지기 때문이다.
* 하드웨어 및 인프라
    * 생각보다 CPU가 좋은 것도 중요하다.
    * CPU가 느리면 GPU가 데이터를 기다리는 시간이 길어져 유휴 상태가 길어진다.
    * 실험 데이터에 의하면 20% ~ 50% 까지의 속도 향상을 얻은 사례가 있다.
<br><br>



## `[딥러닝 데이터 관리 방법]`
* [`Lecture 4: Data Management`](https://fullstackdeeplearning.com/course/2022/lecture-4-data-management/)
<br><br>

### [데이터 관리의 중요성]
* 딥러닝에서 중요한 사실은 문제의 절반 이상이 데이터와 관련된 업무인 것이다.
* 데이터 전처리, 데이터셋 구성, 데이터 탐색, 데이터 정제 등은 많은 시간을 차지한다.
* 데이터 관리는 모델 성능을 향상시킬 수 있는 가장 효과적인 방법이다.
* 데이터 탐색에 10배 더 많은 시간을 투자하고 데이터를 충분히 이해해야 한다.
* 데이터 관리 분야에는 많은 용어와 복잡한 개념들이 있다.
* 하지만 최대한 단순하게 유지하는 것이 중요하다.
<br><br>

### [데이터 소스와 저장]
* 딥러닝에서는 데이터를 GPU가 있는 로컬 파일 시스템으로 가져와야 한다.
* 데이터를 저장하는 추상화 방식은 다음과 같다.
* 파일 시스템
    * 가장 기본적인 데이터 소스는 파일 방식이다.
    * JPEG, MP3, JSON, Parquet 등이 있다.
    * 하지만 버전 관리가 되지 않고 쉽게 덮어쓰거나 삭제될 수 있다.
    * 디스크의 경우 SSD가 HDD보다 훨씬 빠르다.
    * CPU 캐시 > RAM > SATA SSD > 디스크 > 네트워크 순으로 속도가 느려진다.
    * 이미지나 오디오 같은 데이터는 JPEG, MP3와 같은 표준 형식을 따른다.
    * 라벨이나 테이블 형식의 데이터는 JSON 또는 Parquet 형식을 추천한다.
    * Parquet은 기본적으로 높은 압축률을 제공하기 때문에 널리 사용된다.
* 객체 스토리지
    * 파일 시스템 위에 API를 제공하는 개념으로 기본 단위를 객체라고 한다.
    * AWS S3, GCP Cloud Storage, Azure Blob Storage 등이 있다.
    * 버전 관리와 중복성 기능을 내장할 수 있어 쉽게 덮어쓰이지 않는다.
    * S3가 가장 널리 사용되며, 클라우드 내에서는 충분히 빠른 속도를 제공한다.
* 데이터베이스
    * 구조화된 데이터를 저장하고 검색하는데 사용된다.
    * 영구적이고 빠르고 확장 가능한 시스템이다.
    * SQL 데이터베이스 (ex. MySQL)와 NoSQL 데이터베이스 (ex. MongoDB)가 있다.
    * RAM에 있는 것처럼 작동하지만, 디스크에 데이터를 저장해서 안전하다.
    * PostgreSQL은 오픈 소스 데이터베이스로 가장 널리 사용된다.
    * 작은 프로젝트라면 SQLite를 추천한다.
<br><br>

### [DB vs DW vs DL]
* DB
    * 데이터베이스는 주로 온라인 트랜잭션 처리(OLTP)에 사용된다.
    * 일반적으로 행(row) 지향 방식으로 저장된다.
    * OLTP는 실시간 데이터 처리로, 빠른 읽기/쓰기가 중요하다.
* DW
    * 데이터 웨어하우스는 주로 온라인 분석 처리(OLAP)에 사용된다.
    * 일반적으로 열(column) 지향 방식으로 저장된다.
    * OLAP는 대량의 데이터를 분석하는데 최적화되어 있다.
    * ETL 과정을 통해서 여러 데이터를 균일한 스키마로 변환하여 저장한다.
* DL
    * 데이터 레이크는 여러 소스에서 수집한 비정형 데이터의 집합체이다.
    * 정형, 비정형 데이터를 모두 통합하여 저장한다. (요즘 방식)
    * 데이터 웨어하우스와 달리 ELT 방식으로 일단 저장하고 나중에 변환한다.
    * Snowflake, Databricks가 솔루션으로 사용된다.
<br><br>

### [SQL과 DataFrame]
* 데이터와 소통하기 위한 언어는 주로 SQL과 DataFrame이다.
* SQL
    * 구조화된 데이터의 표준 인터페이스이다.
    * 수십년간 존재했고 앞으로도 계속 사용될 것이다.
    * 읽고 쓸 수 있는 능력을 갖추는 것은 데이터 분석의 기본이고 매우 중요하다.
    * DB, DW, DL 모두와 상호작용 하는데 사용된다.
* DataFrame
    * 파이썬에서 Pandas가 가장 널리 사용되는 DataFrame 솔루션이다.
    * R에서는 DataFrame이 기본 데이터 구조로 사용된다.
    * SQL과 유사한 API를 제공하여 데이터 조작을 쉽게 한다.
    * Pandas가 느리다면 Dask는 병렬 처리를 지원하므로 사용해볼 수 있다.
    * GPU가 있다면 Rapids를 사용해 훨씬 빠른 속도로 처리할 수 있다.
<br><br>

### [데이터 파이프라인과 워크플로우 관리]
* DL 모델을 학습하기 위해 데이터를 수집하고 처리하는 과정은 복잡하다.
* 이 과정 중에서 반복 가능한 프로세스를 정의하고 자동화하는 것이 중요하다.
* 워크플로우 매니저
    * Airflow는 비순환 그래프 (DAG) 형태로 태스크를 정의한다.
    * SQL 작업, Python 함수 등을 포함할 수 있다.
    * 작업을 분산하고 실패 시 재시작하고 완료 시 알림을 보낼 수 있다.
    * Airflow의 개선된 버전으로 Prefect, Dagster 등이 있다.
* 오버 엔지니어링
    * 프로젝트에 비해 과도하게 큰 엔지니어링을 피해야한다.
    * 요즘은 코어 수가 높은 CPU와 넉넉한 RAM을 구하기 쉬워졌다.
    * Unix 자체에도 강력한 병렬 처리 도구가 있고 이는 Hadoop보다 훨씬 빠르다.
    * 모든 것을 Unix로 처리하라는 말은 아니고 복잡하지 않은 것도 고려해보는 것이 좋다.
<br><br>

### [피처 스토어]
* 학습과 배포에서 모델이 동일한 방식으로 처리된 데이터를 봐야한다.
* 피처 스토어는 일관성 유지에 도움을 주고 불필요한 재계산을 방지해준다.
* Tecton은 가장 대표적인 SaaS 피처 스토어 솔루션이다.
* Feast는 가장 많이 사용하는 오픈 소스 피처 스토어이다.
* Featureform은 2022년 당시 떠오르는 오픈 소스 피처 스토어였다.
* 요즘에는 Hopsworks 나 AWS, GCP, Azure의 피처 스토어를 많이 사용한다.
<br><br>

### [DL 학습 데이터셋]
* 딥러닝 학습을 위한 데이터셋 활용 방법과 플랫폼을 알고 있어야 한다.
* Hugging Face Datasets
    * 8,000개 이상의 데이터셋(비전, NLP, 음성 등)을 제공한다.
    * 스트리밍 기능: 전체를 다운로드하지 않고도 바로 확인할 수 있다.
    * Parquet 테이블(수천 개의 Parquet 파일로 구성) 을 지원한다.
    * 이미지 URL이 포함된 JSON 파일(예: 'red caps' 데이터셋) 을 지원한다.
    * MP3 및 텍스트 파일(예: 'common voice' 데이터셋) 을 지원한다.
* ActiveLoop
    * 데이터 탐색, 데이터 스트리밍, 데이터 변환 등 다양한 기능을 제공한다.
    * `hub.load`와 같은 간단한 명령어로 데이터셋을 바로 불러올 수 있다.
<br><br>

### [데이터 버전 관리]
* 모델 재현성을 보장하고 성능 저하 시 롤백할 수 있게 해주는 핵심 요소이다.
* 레벨 0: 버전 관리 없음 (비추천)
    * 파일, S3, DB 등에 데이터가 있지만 버전 관리가 되지 않는다.
    * 모델을 배포할 때 코드뿐 아니라 데이터를 함께 배포해야 한다.
    * 데이터가 버전 관리되지 않으면 모델도 사실상 버전 관리되지 않는다.
* 레벨 1: 스냅샷(Snapshot)
    * 모델 학습 때 마다 데이터의 스냅샷을 저장한다.
    * 재학습을 통해 이전 성능으로 돌아갈 수 있다.
    * 하지만 코드만큼 데이터를 쉽게 버전 관리하기는 어렵다.
* 레벨 2: Git LFS(Large File Storage) 활용
    * 데이터를 코드와 동일한 방식으로 버전 관리할 수 있다.
    * 데이터 변경 이력 추적, 롤백, 협업이 가능해진다.
* 레벨 3: 특수화된 데이터 버전 관리 솔루션  
    * DVC (Data Version Control)는 Git LFS 대신 사용할 수 있는 도구이다.
    * 대용량 파일을 직접 저장하고 관리할 수 있다.
    * 커밋 시 데이터를 S3 등에 업로드하여 버전 관리가 가능하다.
    * `dvc run`을 사용하면 데이터와 모델 아티팩트의 생성 경로를 추적할 수 있다.
    * 파이프라인 전체를 재현할 수 있다.
    * Pachyderm 등 다른 특화된 데이터 버전 관리 도구도 존재한다.
<br><br>

### [개인 정보 보호와 민감 데이터 처리]
* 민감한 데이터를 다루는 것은 여전히 연구 영역이라, 아직 솔루션이 별로 없다.
* Federated Learning
    * 로컬 장치의 데이터에 직접 접근하지 않고 글로벌 모델을 학습하는 `연합 학습`이다.
    * 연합 서버가 모델을 로컬에 보내서 학습하고 모델을 다시 서버에 동기화한다.
* Differential Privacy
    * 데이터를 집계하여 개별 데이터 포인트를 식별할 수 없도록 만드는 방법이다.
    * 민감한 데이터를 안전하게 학습할 수 있도록 지원한다.
* Learning on Encrypted Data
    * 암호화된 데이터를 복호화하지 않고 학습할 수 있는지에 대한 연구이다.
    * 데이터의 기밀성을 유지하면서 유용한 모델을 생성하는 방법이다.
<br><br>



## `[딥러닝 데이터 라벨링 방법]`
* [`Lecture 4: Data Management`](https://fullstackdeeplearning.com/course/2022/lecture-4-data-management/)
* [`Lab 6: Data Annotation`](https://fullstackdeeplearning.com/course/2022/lab-6-data-annotation/)
<br><br>

### [데이터 라벨링의 중요성]
* 데이터 라벨링은 딥러닝 모델의 성능에 직접적인 영향을 미친다.
* 정확한 라벨링은 모델이 올바른 패턴을 학습하는 데 필수적이다.
* 라벨링 오류는 모델의 예측 성능을 저하시킬 수 있다.
<br><br>

### [자기지도학습, self-supervised learning]
* 데이터의 일부를 사용해 다른 부분을 라벨링하는 아이디어이다.
* 더 정확하게 말하면 입력 값의 일부가 정답이 되는 것이다.
* NLP에서는 문장의 일부를 마스킹하고 나머지 부분만 보고 마스킹을 예측한다.
* CV에서는 이미지의 일부를 마스킹하고 나머지 부분을 보고 마스킹을 예측한다.
* 멀티 모달에서는 CLIP처럼 이미지와 텍스트 캡션 간의 임베딩 거리를 최소화한다.
<br><br>

### [데이터 증강, data augmentation]
* CV
    * 데이터 증강은 비전 모델 학습에서 필수적인 기법이다.
    * 이미지의 밝기, 대비, 자르기, 기울이기, 뒤집기 등 다양한 변환을 적용한다.
    * 이런 증강으로 레이블 자체를 대체하는 연구도 있다.
    * SimCLR에서는 데이터 증강만으로 학습할 수 있음을 보여준다.
* CV 외
    * 테이블 데이터: 일부 셀을 삭제하여 누락된 데이터를 시뮬레이션할 수 있다.
    * 텍스트: 단어 삭제, 동의어로 대체, 단어 순서 변경 등이 가능하다.
    * 음성: 파일 속도, 일시 정지, 효과 추가, 특정 주파수 제거 등이 가능하다.
<br><br>

### [인간 라벨링, human annotation]
* 사용자 참여 라벨링 (User Labeling)
    * Google 포토처럼 유저에게 라벨링을 참여하도록 유도할 수 있다.
    * 이를 '데이터 플라이휠(data flywheel)'이라고 부른다.
* 전문 라벨링 및 아웃소싱
    * 바운딩 박스, 키포인트, 품사 태깅, 클래스, 캡션 등 다양한 라벨링 작업이 있다.
    * 작업 해석의 모호성을 없애기 위해 완벽한 룰북을 제공해 교육하는 것이 중요하다.
* 라벨링 인력 확보 방법
    * 돈이 많다면 풀 서비스 데이터 라벨링 회사를 활용하는 것이 합리적일 수 있다.
    * 일단 파트타임으로 고용하고 가장 유능한 인력을 품질 관리자로 승진시킬 수 있다.
    * 크라우드소싱 방법이 있으나 품질 문제와 오버헤드가 많아 권장하지 않는다.
<br><br>

### [라벨링 회사와 솔루션]
* 라벨링 회사 선택 방법
    * 회사를 평가할 기준 (golden label)을 위해 일부를 직접 라벨링 해본다.
    * 여러 회사와 미팅을 시도해보고 작업 샘플을 받아본다.
    * 회사에서 받은 샘플을 자신의 golden label과 비교하고 가격을 확인한다.
* 라벨링 솔루션
    * Scale.AI
        * 2022년 당시 가장 지배적인 데이터 라벨링 솔루션이다.
        * API 방식을 통해 작업을 생성하고 결과를 받는다.
    * Labelbox, Superb.ly
        * 다양한 어노테이션 도구이다.
        * 여러 데이터 유형에 대한 라벨링을 지원한다.
    * Label Studio
        * 오픈 소스 솔루션으로 자체 실행이 가능하다.
        * 텍스트, 이미지 등 다양한 인터페이스를 제공한다.
        * 모델 플러그인을 통해 능동 학습(active learning)도 지원한다.
    * Aquarium Learning, Scale Nucleus
        * 모델 성능을 분석하고 라벨링 오류를 탐지할 수 있다.
        * 추가 라벨링이 필요한 부분을 쉽게 선택할 수 있게 돕는 도구이다.
    * Snorkel & Rubrics
        * 약한 지도 학습(weak supervision) 개념을 활용한다.
        * 라벨링 함수를 만들어 소프트웨어가 자동으로 빠르게 라벨링 한다.
<br><br>

### [Label Studio]
* 우리가 실제로 수집하는 데이터는 대부분 레이블이 없는 상태로 제공된다.
* 라벨링 작업을 위해 사용하는 도구가 바로 Label Studio 라는 웹 서비스이다.
* Label Studio를 사용하는 목적은 다음 두 가지이다.
    * Label Studio 웹 서비스를 직접 설정해보는 경험을 쌓는다.
    * 데이터를 직접 라벨링하는 과정을 실습한다.
* 알고리즘 개발이나 배포에 시간을 쓰고 싶다는 생각이 들 수 있지만 잘못된 생각이다.
* 데이터를 직접 다루고 라벨링하는 경험은 모델을 더 깊이 이해하는 데 도움이 된다.
* 데이터 라벨링은 자신의 기술과 파이프라인 이해도를 확인할 수 있는 중요한 분야이다.
* 자세한 사용 방법은 아래 링크를 참고한다.
* [`Lab 6: Data Annotation`](https://fullstackdeeplearning.com/course/2022/lab-6-data-annotation/)
<br><br>



## `[딥러닝 앱 패턴]`
* [`Lecture 5: Deployment`](https://fullstackdeeplearning.com/course/2022/lecture-5-deployment/)
<br><br>

### [딥러닝 앱 패턴: Model in Service]
* 웹 서버가 모델을 직접 포함하는 구조이다.
* Streamlit이나 Gradio 스크립트가 UI를 구축하면서 동시에 모델을 로드하고 실행한다.
* 장점
    * 특히 간단하게 구현할 수 있다.
    * 회사의 기존 웹 인프라를 활용할 수 있다.
    * 모델 개발자가 별도의 환경을 새로 구축할 필요가 없다.
* 단점
    * 웹 서버가 모델과 다른 언어로 작성된 경우 통합이 어렵다.
    * 모델이 서버 코드보다 더 자주 변경될 수 있다.
    * 큰 모델을 웹 서버에서 실행하면 서버 리소스를 많이 소모한다.
    * 일반 웹/모바일 서버는 딥러닝을 돌리기에는 느리고 GPU가 없다.
    * UI와 모델의 확장 속성이 달라 각각 독립적으로 스케일링하기 어렵다.
<br><br>

### [딥러닝 앱 패턴: Batch Prediction]
* 모델을 UI와 분리하여 DB와 직접 상호작용하도록 설계한다.
* 작동 방식
    * 새로운 데이터가 주기적으로 유입된다.
    * 모델이 데이터 포인트별로 실행된다.
    * 추론 결과가 데이터베이스에 저장된다.
* 사용 사례
    * 입력 수가 제한적인 경우 (예: 사용자당 하나의 예측, 고객당 하나의 예측 등)
    * 추천 시스템 (초기 단계)
    * 마케팅 자동화 (예: 잠재 고객 점수 부여)
* 구현 도구
    * 워크플로우 관리 도구: Dagster, Airflow, Prefect
    * 딥러닝/데이터 사이언스 특화 도구: Metaflow
* 장점
    * 구현이 매우 쉽다. (학습에 사용한 도구를 재사용)
    * 별도의 웹 서버가 필요 없다. (예측 결과를 기존 DB에 저장)
    * 확장이 매우 쉽다. (DB는 대규모 확장에 최적화)
    * 지연 시간이 낮다. (DB는 애플리케이션과의 상호작용에 최적화)
* 단점
    * 특정 유형의 모델에 적합하지 않다. (인풋이 복잡한 모델, 인풋 수가 많은 모델)
    * 최신 예측이 아닐 수 있다. (모델 실행 주기 관련)
    * 모델 부패 가능성이 있다. (배치 작업 실패)
<br><br>

### [딥러닝 앱 패턴: Model as a Service]
* 모델을 별도의 온라인 서비스로 운영한다.
* 이 서비스는 백엔드나 클라이언트와 요청-응답 방식으로 상호작용한다.
* 대부분의 딥러닝 기반 제품에서 가장 이상적인 구조이다.
* 복잡한 사용 사례와 무한한 입력에 대해 유연하게 대응할 수 있다.
* 작동 방식
    * 클라이언트 또는 서버가 모델 서비스에 예측 요청을 보낸다.
    * 모델 서비스는 입력에 대한 예측 값을 반환한다.
* 장점
    * 모델에 문제가 있어도 전체 애플리케이션이 중단될 위험이 적다.
    * 모델에 최적화된 하드웨어와 인프라를 선택하고 독립적으로 확장 가능하다.
    * 모델 서비스를 여러 애플리케이션이나 다양한 부분에서 재사용할 수 있다.
* 단점
    * 네트워크 호출이 추가되어 지연 시간이 발생할 수 있다.
    * 별도의 모델 서비스 인프라를 관리해야 하므로 복잡성이 증가한다.
<br><br>

### [REST API와 gRPC]
* REST API는 표준 HTTP 요청을 통해 예측 결과를 제공하는 대표적인 인터페이스이다.
* 서비스가 애플리케이션의 다른 부분과 상호작용하는 "언어" 역할을 한다.
* REST API의 대안
    * gRPC: Google 제품에서 널리 사용되는 고성능 RPC 프레임워크이다.
    * GraphQL: 웹 개발에서 흔히 사용되는 프레임워크이다.
* 입력 형식 표준
    * 모델에 전달하는 입력 형식에 대한 업계 표준은 아직 없다.
    * GCP, Azure, AWS 등 주요 클라우드 제공업체마다 다르다.
    * 향후 업계 표준의 필요성이 대두되고 있다.
<br><br>

### [의존성 관리]
* 모델 예측은 가중치, 전처리, 라이브러리 버전 등 코드와 의존성에 따라 달라진다.
* 모든 의존성이 서버에 정확히 존재해야 일관된 결과를 얻을 수 있다.
* 문제점
    * 개발 환경과 서버 간의 일관성 유지가 어렵다.
    * 모든 환경에서 업데이트를 일관되게 적용하기 어렵다.
    * 라이브러리 버전이 조금만 달라도 모델 동작이 달라질 수 있다.
* 문제 해결에는 두 가지 전략이 존재한다.
1. 모델에 대한 의존성만 제한
    * ONNX(Open Neural Network Exchange)를 사용한다.
    * 오닉스는 다양한 언어/프레임워크에서 일관되게 실행할 수 있는 표준이다.
    * 하지만 라이브러리 변화가 빨라 번역 계층에 버그가 많은 점을 주의한다.
2. 전체 추론 프로그램을 컨테이너로 감싸기
    * Docker와 같은 도구를 사용해 전체 추론 환경을 패키징한다.
    * VM은 전체 운영체제와 애플리케이션을 패키징해 무겁다.
    * Docker는 운영체제 없이 라이브러리와 애플리케이션만 컨테이너에 담아 가볍다.
    * 웹 서버, 데이터베이스, 작업 큐 등 각 기능을 별도 컨테이너로 분리해 실행한다.
<br><br>

### [성능 최적화]
* 딥러닝 모델을 빠르게 실행하고 효율적으로 확장하기 위한 다양한 기술이 있다.
* GPU vs CPU
    * GPU를 사용하면 학습에 사용된 것과 동일한 하드웨어를 활용할 수 있다.
    * 또한 대규모 모델 및 트래픽에 대해 최대 처리량을 제공한다.
    * 하지만 단점으로 설정이 더 복잡하고 가격이 더 비싸다.
    * 모델이 GPU에서 학습되었다고 반드시 GPU에서 호스팅해야 하는 것은 아니다.
    * 초기 버전의 모델은 CPU 호스팅이 더 효율적일 수 있다.
* Concurrency
    * 단일 호스트 머신에서 모델의 여러 복사본을 병렬로 실행하는 기법이다.
    * 로블록스는 이 방법으로 CPU만 사용해 BERT 모델을 하루 10억 건 이상 처리했다.
* Model Distillation
    * 크고 비싼 모델의 동작을 모방하도록 더 작은 모델을 학습하는 기법이다.
    * DistilBERT가 대표적인 예시이다.
* Quantization
    * 모델 추론 시 행렬 곱셈 연산을 더 낮은 정밀도(16비트, 8비트 등)로 실행한다.
    * 정확도 손실은 적으면서 속도 향상 효과가 크다.
    * PyTorch, Hugging Face, TensorFlow Lite 등에서 내장 메서드를 제공한다.
    * 양자화 인식 학습을 통해 더 높은 정확도를 얻을 수 있다.
* Caching
    * 특정 입력에 대한 예측 요청이 반복될 경우, 결과를 캐시에 저장해 재활용한다.
    * Python의 `functools` 라이브러리 등을 사용할 수 있다.
    * 로블록스의 대규모 서비스에서도 중요한 전략이었다.
* Batching
    * 개별 사용자 요청을 모아 배치로 처리해 GPU에서 병렬로 추론을 실행한다.
    * 배치 크기를 조절해 처리량과 지연 시간의 균형을 맞춰야 한다.
    * 지연 시간이 길어질 경우 얼리 스타핑 전략이 필요할 수 있다.
    * 대부분의 모델 호스팅 라이브러리에 배칭 기능이 내장되어 있다.
<br><br>

### [모델 롤아웃, Model Rollouts]
* 롤아웃은 모델 서비스의 버전 관리를 의미한다.
* 새로운 모델 버전을 배포하거나, 트래픽을 분할해 A/B 테스트하는 방법이다.
* 필요한 기능
    * 트래픽의 1%, 10%, 50%를 새 버전에 보내면서 점진적으로 전환한다.
    * 문제 발생 시 즉시 이전 버전으로 복귀할 수 있도록 대비한다.
    * A/B 테스트 등을 위해 트래픽을 여러 버전에 분할한다.
    * 섀도우 트래픽(shadow prediction traffic)으로 테스트한다.
    * (메인 모델과 동일한 입력을 받아 예측은 생성하지만 사용자에게 전송하지 않는 방식)
* 고려 사항
    * 롤아웃은 복잡한 인프라 문제이다.
    * 관리형 옵션이나 팀에서 제공하는 인프라를 사용하는 것이 좋다.
<br><br>

### [관리형 옵션, Managed Options]
* 관리형 옵션은 스케일링 및 롤아웃 등 많은 배포 과제를 대신 처리해준다.
* 클라우드 제공업체 (AWS, GCP, Azure)는 각자의 관리형 서비스를 제공한다.
* 엔드투엔드 딥러닝 플랫폼은 클라우드 제공업체 또는 별도의 플랫폼에서 제공된다.
* BentoML, Cortex, Banana 등 개발자 경험과 성능에 중점을 둔 솔루션도 있다.
* AWS SageMaker
    * 가장 인기 있는 관리형 서비스 중 하나이다.
    * Hugging Face, Scikit-learn 등 표준 형식 모델의 경우 배포가 매우 쉽다.
    * deploy 메서드로 인스턴스 수와 하드웨어를 지정할 수 있다.
    * 전용 웹 서버 및 서버리스 인스턴스 옵션을 모두 제공한다.
    * 표준 모델이 아닌 복잡한 작업은 컨테이너를 직접 배포해야 한다.
    * 전용 인스턴스는 원시 EC2보다 비쌀 수 있다.
<br><br>



## `[딥러닝 앱 배포 방법]`
* [`Lecture 5: Deployment`](https://fullstackdeeplearning.com/course/2022/lecture-5-deployment/)
<br><br>

### [딥러닝 배포의 중요성]
* 딥러닝 모델을 학습하는 것은 시작에 불과하다.
* 제품 구축을 위해서는 모델을 실제 프로덕션 환경에 배포해야 한다.
* 배포는 모델의 잠재된 결함을 발견하고 real world에서 테스트하는 중요한 과정이다.
* 핵심 사고방식은 '일찍 배포하고 자주 배포하라'이다.
* 또한, 간단하게 시작하고 필요에 따라 복잡성을 추가하는 원칙을 강조한다.
<br><br>

### [프로토타입 배포]
* 프로덕션 모델의 첫 프로토타입을 구축하는 단계이다.
* 직접 모델을 사용해보고 친구나 동료들과 공유하여 초기 피드백을 받는다.
* 주요 도구
    * Gradio: 몇 줄의 코드로 간단한 사용자 인터페이스를 만들 수 있다.
    * Streamlit: Gradio보다 더 유연하고 Python만으로 복잡한 UI를 구축할 수 있다.
    * Hugging Face Spaces: Hugging Face 생태계에 내장된 배포 도구이다.
* 모범 사례
    * 기본적인 UI를 만들어 모델과 직접 상호작용하고 피드백을 받는다.
    * 노트북에서만 실행하지 말고, 웹 URL을 통해 모델을 공유한다.
    * 이는 향후 지연 시간(latency) 등 트레이드오프를 고려하는 데 도움이 된다.
    * 이 단계는 프로토타입이므로 부담 갖지 말고 빠르게 완성하는 것이 중요하다.
* 한계점
    * 프로토타입은 최종 솔루션이 될 수 없다.
    * 주요 도구들은 훌륭하지만 완전히 커스텀된 UI를 구축할 수 없다.
    * 동시에 요청이 많아지면 시스템의 확장 한계에 도달할 수 있다.
    * 하지만 한계에 부딪히면서 딥러닝 배포의 복잡성을 이해하게 된다.
<br><br>

### [수평 확장]
* 단일 서버로 처리하기에 트래픽이 많을 때 여러 서버에 트래픽을 분산하는 방식이다.
* 각 서버에 서비스 복사본이 실행된다.
* 로드 밸런서(load balancer)가 트래픽을 라우팅한다.
1. 컨테이너 오케스트레이션
    * Kubernetes가 가장 널리 사용된다.
    * Docker와 연동해 컨테이너화된 분산 애플리케이션을 관리한다.
    * 딥러닝 배포만이 목적이라면 Kubernetes는 과할 수 있다.
    * Kubeflow Serving 등은 Kubernetes 위에서 모델 배포를 쉽게 해준다.
2. 서버리스(Serverless)
    * 인프라 관리 부담이 적은 대안이다.
    * 앱 코드와 의존성을 Docker 컨테이너로 패키징한다.
    * 패키징된 컨테이너를 AWS Lambda 등에 배포한다.
    * 서비스가 예측 함수를 실행하고 확장과 로드 밸런싱을 자동 처리한다.
    * 프로토타입 이후의 시작점으로 적합하다.
    * "서버가 없다면 다운될 일도 없다"는 개념에 부합한다.
* 서버리스 장점
    * 스케일링과 로드 밸런싱을 서비스가 담당해서 편하다.
    * 실제 실행 시간에만 비용 발생하므로 트래픽이 적거나 간헐적일 때 유리하다.
* 서버리스 단점
    * 대형 모델은 한계가 있다.
    * 유휴 후 첫 요청 시 지연 시간이 길어질 수 있다.
    * 복잡한 파이프라인을 구축하기 어렵다.
    * 상태 관리(캐싱 등) 제한이 있다.
    * 대부분 CPU 전용이나 서버리스 GPU 서비스가 등장하고 있다.
<br><br>

### [엣지 배포]
* 여기서 엣지는 사용자의 디바이스를 의미한다.
* 모델을 웹 서버에서 완전히 분리하여 엣지로 이동시키는 방식이다.
* 모델 가중치를 클라이언트 디바이스로 전송한다.
* 클라이언트가 직접 모델을 로드하여 상호작용한다.
* 엣지 배포 필요 상황
    * 인터넷 연결이 불안정할 때 (ex. 자율 주행 차량 등)
    * 엄격한 데이터 보안/프라이버시 요구사항이 있을 때 (ex. Apple 기기)
    * 매우 낮은 지연 시간이 요구될 때 (ex. 실시간 로봇 제어 등)
* 장점
    * 최저 지연 시간을 제공한다.
    * 인터넷 연결이 필요없다.
    * 데이터가 디바이스를 벗어나지 않아 보안성이 높다.
    * 각 사용자가 자체 하드웨어를 사용하므로 서버 확장성 부담이 적다.
* 단점
    * 엣지 디바이스의 하드웨어 리소스가 매우 제한적이다.
    * 파이토치 대비 ONNX같은 엣지용 도구는 미성숙하고 사용이 어렵다.
    * 가중치 전체를 보내야 하므로 모델 업데이트가 복잡하다.
    * 원시 데이터 접근이 어려워 오류 감지 및 디버깅이 매우 어렵다.
    * 웹 배포에 비해 복잡성이 크게 증가한다.
<br><br>

### [엣지 배포 프레임워크]
* 모델 학습과 배포 디바이스에 따라 적절한 프레임워크를 선택해야 한다.
* 주요 엣지 프레임워크
    * Nvidia 디바이스: TensorRT
    * Android 디바이스: Android Neural Networks API
    * Apple 디바이스: Core ML
    * PyTorch 지원 디바이스: PyTorch Mobile
    * TensorFlow 지원 디바이스: TensorFlow Lite
    * 브라우저: TensorFlow.js, ONNX.js
* 사실 ONNX를 사용하면 대부분의 디바이스에서 실행할 수 있다.
* ONNX는 다양한 프레임워크에서 모델을 변환하고 실행할 수 있는 표준이다.
<br><br>

### [엣지 배포의 핵심]
1. 타겟 디바이스를 염두에 두고 아키텍처를 선택해야 한다.
    * 완벽한 모델을 먼저 만들고 나중에 디바이스에 맞추지 않도록 주의한다.
    * 증류, 양자화 등으로 2~10배 정도의 개선만 기대할 수 있다.
    * 타겟 환경에 비해 100배 이상 크거나 느리면 피하는 것이 좋다.
2. 로컬에서 반복 개발해본다.
    * 모든 변경 사항을 실제 디바이스에서 테스트할 필요 없다.
    * 로컬에서 반복 개발하여 디바이스에 배포하기 전에 문제를 조기에 발견한다.
    * 모델 크기나 지연 시간이 점진적으로 증가하는지만 확인한다.
    * 이를 위한 메트릭이나 테스트를 준비하는 것이 좋다.
3. 디바이스 튜닝은 추가적인 위험으로 간주하고 반드시 테스트한다.
    * 모델을 디바이스에 배포하기 전에 항상 실제 디바이스에서 테스트해야 한다.
    * 라이브러리 때문에 개발 환경과 실제 디바이스 간에 미묘한 차이가 발생할 수 있다.
4. 폴백(Fallback) 메커니즘을 내장한다.
    * 모델 실패, 잘못된 버전 배포, 느린 실행을 대비해 폴백 메커니즘을 내장한다.
    * 폴백은 모델이 실패할 때 대체 동작을 제공하는 기능이다.
    * 예를 들어, 모델이 실패하면 이전 버전의 모델을 사용하거나 기본값을 반환한다.
<br><br>



## `[딥러닝 웹 배포 방법]`
* [`Lab 7: Web Deployment`](https://fullstackdeeplearning.com/course/2022/lab-7-web-deployment/)
<br><br>

### [PyTorch의 TorchScript]
* 학습 단계에서는 PyTorch 모델을 사용하지만, 배포를 위해서는 변환이 필요하다.
* 이때 사용하는 것이 TorchScript이다.
* 변환의 필요성
    * 휴대성 향상: 다양한 환경에 쉽게 배포할 수 있도록 한다.
    * 경량화: 모델 크기가 작아지고, 불필요한 종속성이 줄어든다.
    * 종속성 감소: Python 런타임, PyTorch, W&B, 라이브러리 없이도 실행 가능하다.
    * 간소화된 추론 코드: `torch.jit.load` 한 줄로 불러올 수 있다.
* 변환 과정
    1. GPU에서 모델을 학습하고 체크포인트를 스토리지에 저장한다.
    2. 일단 모델을 Lightning 모듈로 다시 로드한다.
    3. `to_torchscript` 메서드를 호출해 TorchScript 형식으로 변환한다.
    4. 변환된 TorchScript 모델은 클라우드 스토리지에 저장된다.
<br><br>

### [Gradio 활용]
* CLI는 실제 사용자 인터페이스로는 적합하지 않다.
* 사용자는 원래 데이터를 직접 보고 조작하며 모델과 상호작용하길 원한다.
* Gradio의 중요성
    * UI 개선: 사용자가 실제로 데이터를 보내고 예측을 받는 방식에 가깝게 해준다.
    * 간단한 UI 구축: Gradio는 입출력이 있는 Python 함수만 있으면 UI를 래핑할 수 있다.
* Gradio UI 구축 방법
    * 핵심 구성 요소: 상호작용할 Python 함수(ex. predict)와 입출력 유형을 지정한다.
    * 추가 기능: 제목, 설명, README, 예제 입력 등을 쉽게 설정할 수 있다.
    * 실행: launch 메서드만 실행하면 UI가 생성되고 CLI에서 쉽게 실행 가능하다.
* Gradio의 공유 및 API 기능
    * 공개 URL: Gradio는 실행 시 누구나 접근 가능한 공개 URL을 제공한다.
    * API 자동 생성: UI 생성과 동시에 Gradio는 API도 함께 제공한다.
    * API 상호작용: curl, Python requests 등으로 API와 상호작용할 수 있다.
<br><br>

### [모델 서비스 구축]
* 초기에는 모델과 서버를 동일한 하드웨어에서 실행하는 것이 직관적일 수 있다.
* 하지만 결국에는 모델 백엔드를 UI 프론트엔드와 분리해야 한다.
* 다시 말해, 모델을 서비스로(model as a service) 구축해야 한다.
* 장점
    * 모델과 UI를 독립적으로 확장할 수 있다.
    * 백엔드와 프론트엔드를 서로 독립적으로 개발할 수 있다.
    * UI는 로컬에서 실행하고, 모델은 AWS 인프라 등 원격 서버에서 실행할 수 있다.
* 서버리스 클라우드 함수
    * 인프라 팀 없이도 모델 서빙을 쉽게 확장할 수 있는 방법이다.
    * 주요 클라우드 제공업체의 서버리스 클라우드 함수를 사용하면 된다.
    * 24시간 내내 실행되지 않고 필요할 때만 실행된다.
    * 사용자 세션의 상태를 관리하지 않는다.
    * AWS Lambda가 대표적인 예시이다.
    * AWS Lambda는 자체 URL을 제공하므로 curl이나 requests로 직접 요청을 보낼 수 있다.
    * 구현하기
        1. TorchScript를 기반으로 ParagraphTextRecognizer 클래스를 생성한다.
        2. 모델의 predict 함수를 래핑하는 핸들러 함수를 작성한다.
        3. 핸들러는 JSON Blob 형태로 들어오는 이벤트를 처리한다.
        4. 이미지 데이터를 추출하여 모델의 predict 함수에 전달한다.
        5. 모델의 출력을 다시 JSON 형태로 패키징하여 반환한다.
<br><br>

### [영구적인 공개 URL 및 프로덕션 배포]
* Gradio가 제공하는 URL은 72시간 동안만 유효하다.
* 따라서 안정적인 배포를 위해서는 자체적인 공개 URL 설정이 필요하다.
* 임시 URL 생성
    * Ngrok을 이용해 로컬 Gradio 서비스를 외부에서 접근 가능하게 만들 수 있다.
    * Ngrok의 프리 티어는 공개 URL과 HTTPS 보안 통신을 모두 제공한다.
    * 하지만 서비스 재시작 시 URL이 변경된다.
* 프로덕션 환경 전환
    * 웹 서비스를 주피터 노트북이나 Colab에서 실행하는 것은 불가능하다.
    * 클라우드 제공업체(예: AWS EC2)에 전용 서버를 설정하는 것이 좋다.
* 도커를 통한 자동화
    * 설정 과정을 자동화하고 요구 사항 및 명령 실행 관리를 간소화해야 한다.
    * Docker 파일을 빌드하여 컨테이너 이미지를 생성하고 Docker Hub에 푸시한다.
    * 대상 머신에서 이미지를 풀(pull)하여 docker run 명령으로 실행한다.
<br><br>



## `[딥러닝 재학습 전략]`
* [`Lecture 6: Continual Learning`](https://fullstackdeeplearning.com/course/2022/lecture-6-continual-learning/)
<br><br>

### [재학습 전략의 중요성]
* 현실 세계의 데이터 분포는 끊임없이 변화한다.
* 딥러닝 모델은 배포된 후에도 지속적으로 학습하고 적응해야한다는 뜻이다.
* 잘 만든 딥러닝 모델이라고 해도 실제로 배포하면 충분히 성능이 떨어질 수 있다.
* 최악의 경우는 모델을 재학습하고 다시 배포하는 ad-hoc 방식이다.
* 좋은 시스템 아키텍처는 배포는 1번만 하고 지속적인 학습을 하도록 설계된 것이다.
<br><br>

### [Continual Learning 루프]
* Continual Learning은 프로덕션 환경의 데이터에 적응하는 것을 목표로 한다.
* 이는 학습 프로세스의 외부 루프로 볼 수 있다.
* 이 루프의 각 단계는 다음 단계로 출력을 전달하고 일련의 규칙에 의해 정의된다.
* 이러한 모든 규칙을 합쳐 `재학습 전략(Retraining Strategy)`이라고 부른다.
* 1단계: 로깅
    * 핵심 질문: 어떤 데이터를 실제로 저장해야 하는가?
    * 목적: 다운스트림 분석에 사용
    * 출력: 무한한 프로덕션 데이터 스트림
* 2단계: 데이터 큐레이션
    * 핵심 규칙: 무한한 스트림에서 어떤 데이터를 우선순위로 지정할 것인가?
    * 목적: 레이블링 및 재학습에 사용
    * 출력: 유한한 수의 후보 학습 데이터 포인트 저장소
* 3단계: 재학습 트리거
    * 핵심 질문: 언제 실제로 재학습을 해야 하는가?
    * 목적: 재학습 시작
    * 출력: 재학습 작업을 시작하라는 신호
* 4단계: 데이터셋 형성
    * 핵심 규칙: 재학습 작업에 사용할 데이터의 하위 집합은 무엇인가?
    * 목적: 재학습에 포함될 정확한 데이터 포인트 지정
    * 출력: 저장소의 뷰
* 5단계: 오프라인 테스트
    * 핵심 규칙: 배포할 준비가 되었다고 어떻게 합의할 것인가?
    * 목적: 명확한 승인 절차를 거친 모델
    * 출력: 모델의 성적표
* 6단계: 배포 및 온라인 테스트
    * 핵심 규칙: 이 배포가 성공적이었는지 어떻게 알 수 있는가?
    * 목적: 모델이 실제로 프로덕션에서 잘 작동하는지 확인
    * 출력: 모델을 완전히 롤아웃하라는 신호.
* 엔지니어의 역할은 모델을 직접 재학습하는 것이 아니다.
* 재학습 전략을 감독하고 시간이 지남에 따라 전략 자체를 개선하는 것이다.
* 전략에 따른 모델 개선 지표를 보고 전략에 대한 규칙을 조정한다.
<br><br>

### [루프 개선: 로깅]
* 기본 권장 사항은 모든 데이터를 로깅하는 것이다.
* 스토리지는 저렴하기 때문에 데이터를 가지고 있는 것이 없는 것보다 낫다.
* 예외 상황
    * 트래픽이 너무 많은 경우
    * 데이터 프라이버시 문제가 있는 경우
    * 엣지(edge)에서 모델을 실행하는 경우
* 대안 :프로파일링(Profiling)
    * 엣지에서 직접 데이터 통계 프로파일을 계산한다.
    * 데이터 전체를 클라우드로 보내지 않는다.
    * 데이터 보안, 스토리지 비용 최소화에 유리하다.
    * 꼬리 분포(tails)의 이벤트를 놓치지 않는다.
* 대안: 샘플링(Sampling)
    * 특정 데이터 포인트만 클라우드로 보낸다.
    * 추론 리소스에 미치는 영향이 적다.
    * 디버깅 및 재학습을 위해 원시 데이터에 접근할 수 있다.
<br><br>

### [루프 개선: 데이터 큐레이션]
* 무한한 프로덕션 데이터를 유한한 데이터로 변환한다.
* Random Sampling
    * 가장 기본적인 방법이다.
    * 하지만 모델이 개선될수록 일부 데이터만 추가 개선에 기여한다.
    * 희귀 클래스나 이벤트를 놓칠 수 있다.
* Stratified Sampling
    * 하위 모집단에서 특정 비율의 데이터를 샘플링한다.
    * 클래스 균형을 맞춰서 샘플링하는 것이다.
    * 모델이 편향되지 않도록 클래스 간 균형을 맞추는 데 유용하다.
* User-driven curation
    * 사용자 피드백을 기반으로 데이터를 선택한다.
    * (ex. 사용자가 예측에 만족하지 않아 이탈, 비추천 버튼 클릭)
    * 가장 쉽고 효과적인 방법이다.
* Manual error analysis
    * 오류 분석해 함수나 규칙을 작성하여 데이터를 수집한다.
    * Similarity-based curation
        * 최근접 이웃 유사성을 사용하여 유사한 데이터 포인트를 찾는다.
        * 희귀하지만 쉽게 감지할 수 있는 이벤트에 좋다.
    * Projection-based curation
        * 오류 사례를 감지하는 함수를 작성한다.
        * 미묘한 오류 모드에 좋다.
* Active Learning
    * 모델 성능을 가장 많이 향상시킬 데이터를 알고리즘적으로 결정한다.
    * Scoring functions
        * 각 데이터에 점수를 할당하여 유용성을 식별하는 함수들을 작성한다.
        * 모델이 매우 확신하지 못하는 데이터
        * 모델이 오류를 만들 것으로 예상되는 데이터
        * 학습하지 않은 데이터와 매우 다른 데이터
        * 분포를 가장 잘 나타내는 데이터
        * 학습에 큰 영향을 미칠 것으로 예상되는 데이터
    * Uncertainty-based sampling
        * 모델이 예측에 대해 가장 불확실한 데이터 포인트를 선택한다.
        * (ex. 분류에서 예측 확률이 0.5에 가까운 경우)
        * 구현이 매우 간단하고 괜찮은 결과를 낸다.
        * 가장 많이 사용되는 방법이다.
<br><br>

### [루프 개선: 재학습 트리거]
* 자동화된 재학습으로 전환하여 시간을 절약하고 모델 성능을 향상시킬 수 있다.
* 모델 성능을 자동화된 방식으로 재현할 수 있어야 한다.
* 모델을 매우 자주 재학습해야 하는 경우 자동화를 고려한다.
* Periodic retraining
    * 가장 간단한 접근 방식으로 주기적으로 재학습 한다.
    * (ex. 일주일에 한 번 재학습, 지난달 데이터로 재학습)
* Performance triggers
    * 정확도와 같은 메트릭에 트리거를 설정한다.
    * 정확도가 사전 정의된 임계값 아래로 떨어질 때만 재학습한다.
    * 예상치 못한 변화에 더 빠르게 반응하고 필요할 때만 재학습한다.
    * 하지만 재학습 시점을 미리 알 수 없고 운영이 복잡하다.
* Online learning
    * 모든 데이터가 들어올 때마다 매번 다시 재학습한다.
    * 실제로는 잘 사용되지 않는다.
* Online adaptation
    * 모델 자체를 재학습하지 않고 정책(policy)을 적응시킨다.
    * 정책은 모델의 예측을 사용자가 실제로 보는 것으로 바꾸는 규칙 집합이다.
    * (ex. 분류에서 임계값을 0.5에서 0.6으로 변경)
    * 데이터가 자주 변하거나 모델을 자주 학습하기 어려운 경우에 유용하다.
<br><br>

### [루프 개선: 데이터셋 형성]
* 모든 데이터로 학습
    * 새로운 데이터가 들어오면 큐레이션하고 기존 데이터셋에 추가한다.
    * 데이터 버전 관리와 큐레이션 규칙 추적이 중요하다.
* 데이터가 너무 많은 경우
    * Sliding window
        * 가장 최근의 데이터를 포함하도록 데이터 윈도우를 이동시킨다.
        * 가장 오래된 데이터는 제거되고 가장 최근의 데이터가 포함된다.
    * Online batch selection
        * 각 학습 단계 전에 큰 사이즈의 배치를 샘플링한다.
        * label aware selection function에 따라 항목 순위를 매긴다.
        * 상위 N개 항목으로 학습한다.
* Continual fine-tuning
    * 기존 모델을 새 데이터에만 학습시킨다.
    * 비용 효율성이 매우 높다.
    * 하지만 모델이 과거에 학습한 내용을 쉽게 잊어버릴 수 있다.
    * 재앙적 망각(catastrophic forgetting) 문제가 발생할 수 있다.
    * 평가 시스템을 제대로 설계하지 않으면 성능이 저하될 수 있다.
<br><br>

### [루프 개선: 오프라인 테스트]
* 새 모델이 충분히 좋은고 기존 모델보다 나은지 보고서를 작성한다.
* 보고서 필수 내용
    * 관련된 모든 메트릭 (ex. 정확도, 정밀도, 재현율 등)
    * 특정 데이터 슬라이스(slices)의 결과 (ex. 사용자 연령, 계정 연령)
    * 정의된 모든 엣지 케이스 (ex. 잘못된 문법, 특정 신조어)
* 평가 데이터셋의 동적 특성
    * 학습 데이터셋과 마찬가지로 평가 데이터셋도 동적으로 만들어야 한다.
    * 새로운 데이터를 큐레이션할 때 평가 데이터셋에도 추가해야 한다.
    * 평가 데이터셋도 버전 관리를 해야 한다.
    * 모델이 새로운 데이터에 잘 일반화되는지 확인할 수 있다.
* Expectation 테스트
    * 관계를 아는 예제 쌍을 사용하여 모델의 일반화 성능을 테스트한다.
    * (ex. 이미지를 90도 회전시켜도 같은 객체로 분류될 것으로 예상)
    * 모델이 예측 가능한 방식으로 일반화되는지 확인한다.
<br><br>

### [루프 개선: 배포 및 온라인 테스트]
* 단계별 배포 전략을 통해 새로운 모델을 안전하게 프로덕션에 배포한다.
* 각 단계에서 모델의 성능과 안정성을 검증한 후 다음 단계로 진행한다.
* 문제가 발생하면 즉시 이전 버전으로 롤백할 수 있는 체계를 구축한다.
* Shadow mode
    * 실제 사용자에게 배포하기 전에 모델을 쉐도우 모드에서 실행한다.
    * 백그라운드에서 예측을 수행하지만 결과는 사용자에게 보이지 않는다.
    * 실제 데이터로 모델의 성능과 안정성을 검증할 수 있다.
    * 예상치 못한 오류나 성능 저하를 사전에 발견할 수 있다.
* A/B test
    * 이전 모델보다 새 모델의 성능이 더 나은지 검증한다.
    * 사용자 그룹을 무작위로 나누어 서로 다른 모델을 제공한다.
    * 사용자 행동, 만족도, 비즈니스 메트릭을 비교 분석한다.
    * 통계적으로 유의미한 차이가 있는지 검증한다.
* Gradual rollout
    * 성공적인 A/B 테스트 후 모든 사용자에게 모델을 점진적으로 롤아웃한다.
    * 작은 비율의 사용자부터 시작하여 단계적으로 확대한다.
    * (ex. 5% → 25% → 50% → 100%)
    * 각 단계에서 모델 성능과 시스템 안정성을 모니터링한다.
* Rollback
    * 롤아웃 중에 문제가 발생하면 이전 버전의 모델로 롤백한다.
    * 자동화된 롤백 시스템을 구축하여 빠른 대응이 가능하도록 한다.
    * 문제 원인을 파악하고 수정한 후 다시 배포를 시도한다.
    * 롤백 기준과 절차를 사전에 명확히 정의해야 한다.
<br><br>

### [루프 개선 워크플로우]
* 모델의 문제를 감지하고 지속적으로 개선하는 워크플로우의 예시이다.
* 1단계: 알림 발생
    * 사용자 피드백이 나빠졌다는 알림을 받는다.
    * 모니터링 시스템에서 성능 저하를 감지한다.
* 2단계: 조사
    * Observability 도구를 사용하여 문제를 조사한다.
    * (ex. 사용자 피드백, 성능 메트릭, 로그 데이터)
    * 하위 그룹 분석과 원시 데이터를 살펴본다.
    * 문제가 주로 신규 사용자에게 집중되어 있다는 것을 발견한다.
* 3단계: 오류 분석
    * 신규 사용자가 보내는 데이터를 분석한다.
    * 모델이 왜 더 나쁜 성능을 보이는지 원인을 파악한다.
    * (ex. 일반 텍스트 외에 이모티콘이 포함된 텍스트가 입력)
* 4단계: 모니터링 체계 구축
    * 신규 사용자를 관심 코호트로 정의한다.
    * 앞으로 신규 사용자의 성능이 저하되면 알림을 받도록 한다.
    * 이모티콘이 포함된 데이터를 감지하는 새 프로젝션을 정의한다.
    * 신규 메트릭으로 추가하여 성능 차이를 볼 수 있도록 한다.
* 5단계: 데이터 큐레이션 및 재학습
    * 저장소에서 이모티콘이 포함된 과거 예시를 검색한다.
    * 모델 개선에 사용할 데이터를 선별한다.
    * 이모티콘 예시를 새로운 테스트 케이스로 추가한다.
    * 학습 데이터셋에 큐레이션하여 재학습을 수행한다.
* 6단계: 새 모델 비교 보고서
    * 학습된 새 모델에 대한 보고서를 받는다.
    * 새로 정의된 코호트에 대한 성능 정보가 포함된다.
    * 이모티콘 엣지 케이스 데이터셋에 대한 결과도 포함된다.
* 7단계: 배포
    * 수동 배포인 경우 모델을 배포한다.
    * 자동화된 배포 파이프라인을 통해 단계적으로 롤아웃한다.
* 이러한 단계를 통해 지속적인 개선 루프가 완료된다.
* 문제 발견부터 해결까지의 전체 프로세스가 체계적으로 관리된다.
<br><br>



## `[AI 팀과 프로젝트 관리 방법]`
* [`Lecture 8: ML Teams and Project Management`](https://fullstackdeeplearning.com/course/2022/lecture-8-teams-and-pm/)
<br><br>

### [AI 팀의 구성과 역할]
* PM
    * 프로젝트 매니저
    * 목표
        * AI팀, 비즈니스 팀 간의 협력과 우선순위 설정
        * 요구사항을 충족하도록 실행 감독
    * 산출물
        * 디자인 문서, 와이어 프레임, 작업 계획
    * 도구
        * Jira, Notion
    * 필요 기술
        * 기존 PM 배경과 AI 개발 프로세스에 대한 깊은 이해
        * AI 팀과의 협업 경험, 데이터 사이언티스트 경험, AI 엔지니어 경험
        * 개인적인 AI에 대한 관심
* MLOps
    * 목표
        * 모델 배포를 자동화하고 확장성 향상
        * 개별 인원들의 작업 부담을 줄이는데 필요한 인프라 구축
    * 산출물
        * 인프라, 공유 도구
    * 도구
        * AWS, Kafka, Airflow, Docker, Kubernetes
    * 필요 기술
        * SW 엔지니어링 역량과 AI 요구사항 이해
        * 데이터 엔지니어 경험, 플랫폼 엔지니어 경험
        * AI 엔지니어에서 전환하는 경우도 존재
* AI 엔지니어
    * 목표
        * AI 제품을 구동하는 모델 학습, 배포, 유지보수
        * 학습뿐만 아니라 배포와 프로덕션까지 포함
    * 산출물
        * 모델, 코드, 데이터 파이프라인
    * 도구
        * PyTorch, TensorFlow, Docker
    * 필요 기술
        * AI 기술과 일부 SW 엔지니어링
        * SW 엔지니어가 AI를 독학한 경우
        * AI 관련 학위 소유자가 SW 엔지니어링을 전향한 경우
* 데이터 사이언티스트
    * 목표
        * 높은 성능의 모델 학습
        * 최신 기술을 반영한 모델 학습
    * 산출물
        * 학습된 모델, 모델 보고서, 코드 저장소
    * 도구
        * PyTorch, TensorFlow, Jupyter Notebook
    * 필요 기술
        * AI 전문가로 대학원 학위 필요
        * 문제를 해결하는데 중요한 연구에 집중하는 능력
        * 물리, 통계, 수학 전공의 인재가 AI 교육을 받은 경우도 존재
<br><br>

### [AI 인재 채용]
* AI 인재 부족 시대가 도래했다.
* AI 인재 중에서 특히 생산 경험을 가진 인재는 더욱 부족하다.
* PM과 MLOps
    * 기존 SW 엔지니어링 경험이 중요하다.
    * 추가적으로 AI 프로젝트 구축 혹은 협업 경험이 있는 사람을 찾는다.
* AI 엔지니어
    * 유니콘 AI 엔지니어에 대한 환상을 피해야 한다.
    * 최신 기술 습득, 모델 구현, 수학적 이해, 새 모델 발명, 인프라 구축, 파이프라인 구축, 모델 배포, 모니터링, 모든 것을 다 요구하는 채용 공고는 피해야 한다.
    * 이런 사람은 세상에 존재하지 않는다.
    * SW 엔지니어링 기술을 최우선으로 고려해야 한다.
    * 이후에 AI에 대한 관심과 기본적인 지식이 있다면 AI는 교육하면 된다.
    * 최근 컴공 학부생들은 AI에 대한 경험을 가지고 있다.
    * 따라서 잠재력 있는 주니어를 채용하는 것도 좋은 방법이다.
    * 모든 AI 엔지니어가 DevOps 전문가 이거나 논문 구현을 다 할 수 없다.
    * 실제로 당장 필요한 구체적인 스킬에 집중해서 채용한다.
* 데이터 사이언티스트
    * 양보다 질 좋고 창의적이고 적용 가능한 연구를 한 사람을 찾는다.
    * 회사에 직면한 문제를 독립적으로 인식하고 해결하려는 능력이 중요하다.
    * 숙련된 연구원이 있다면 인접 분야(통계, 수학) 인재를 채용하여 교육할 수 있다.
<br><br>

### [AI 인재 유치 방법]
* 최첨단 도구와 기술
    * 최신 연구와 최첨단 기술을 활용하는 환경을 제공한다.
    * AI 엔지니어가 최신 기술을 사용하고 실험할 수 있는 환경을 제공한다.
* 지식 습득 기회
    * 팀 내 학습 문화를 구축한다.
    * 전문성 개발 및 컨퍼런스 예산을 지원해 성장을 독려한다.
* 우수한 인재와 협업
    * 고위 프로필의 인재를 채용한다.
    * 기존 팀원들이 블로그나 논문을 출판하도록 지원한다.
    * 팀의 역량을 외부에 알리는 것이 중요하다.
* 흥미로운 데이터셋
    * 독특하고 풍부한 데이터셋을 보유하고 있다면 이를 강조한다.
    * AI 인재가 다뤄야할 데이터셋은 채용에 큰 영향을 미친다.
* 의미 있는 업무
    * 회사의 미션과 AI의 영향력을 강조한다.
    * 업무가 중요하고 의미 있다는 것을 보여준다.
<br><br>

### [AI 직무 면접관 이라면]
* 유니콘 AI 엔지니어를 찾는 함정을 피해야한다.
* 일단 필요한 모든 기술의 최소 기준을 정리해서 적는다.
* 지원자의 강점을 검증하는 것을 위주로 채용한다.
* 지원자의 약점은 최소 기준을 충족하는 지만 확인한다.
* 리서처는 창의적인 사고 능력과 최소한의 SW 능력이 필요하다.
* 엔지니어는 훌륭한 SW 기술과 AI에 대한 최소 지식이 필요하다.
<br><br>

### [AI 직무 취업자 라면]
* 컨퍼런스 참석과 온라인 강의 수강으로 AI에 대한 관심을 표현한다.
* AI 스킬도 중요하지만 SW 엔지니어링 스킬을 갖추는 것이 더 중요하다.
* 특정 연구 분야를 종합하거나 알고리즘을 설명하는 블로그를 작성한다.
* 가장 중요한 것은 AI 프로젝트에 대한 수행 능력 입증이다.
* 사이드 프로젝트를 통해 개인적인 아이디어, 논문 등을 구현한다.
* 캐글 수상, 논문 출판 등으로 창의적인 사고 능력을 입증한다.
<br><br>

### [AI 기반 제품 설계]
* 대부분은 AI 기반 제품에 대해 비현실적인 기대를 가진다.
* 그러나 실제 AI 제품은 `퍼즐을 풀도록 훈련된 강아지`에 가깝다.
* 강아지는 아주 어려운 퍼즐을 풀 수 있지만, 실패할 가능성이 있다.
* 그리고 실패하는 방식은 전혀 예상하지 못하는 경우가 많다.
* 또한 특정 도메인을 벗어나면 동작하지 않고 피드백이 없으면 학습이 어렵다.
* 설계 목표는 사용자의 기대와 현실 사이의 간극을 메우는 목표를 잡는다.
* 시스템 설명
    * AI 기반이라는 것보다는 진짜 문제 해결에 집중해야 한다.
    * 모델의 한계를 인지하고 동작하지 않을 때를 대비한다.
* 인간 개입
    * 자동화에 과도하게 의존하지 않고 인간 개입을 설계한다.
    * 사용자가 모델의 예측을 확인하거나 수정할 수 있는 인터페이스를 제공한다.
    * 사용자가 시스템의 전권을 제어할 수 있는 방법을 마련한다.
    * 확신이 낮은 응답은 답을 줄 수 없도록 설계하는 것이 좋다.
* 유저 피드백 루프
    * 추천 클릭, 복사 여부 등 암시적인 피드백을 구현한다.
    * 좋아요 버튼과 같이 명시적인 피드백을 제공한다.
    * 두개로 분류하지 않고 만족도가 몇점인지 나타낼 수도 있다.
    * 사용자가 모델 예측을 직접 레이블링하거나 수정하도록 하면 매우 유용하다.
<br><br>