# 📓Paper List
* Understanding and Improving Robustness of Vision Transformers through Patch-based Negative Augmentation
* QIN, Yao, et al. Understanding and improving robustness of vision transformers throug
* NeurIPS 2022.
<br><br>

## [`논문 요약 양식`]

### [저자의 의도]
* 
<br><br>

### [기존 문제점]
* 
<br><br>

### [해결 아이디어]
* 
<br><br>

### [추가로 볼 레퍼런스]
* 
<br><br>

### [내 아이디어]
* 
<br><br>



## [`메모`]

### [배경 지식]
* robustness
    * 모델이 입력의 다양한 변화와 노이즈에 얼마나 견고한지에 대한 지표.
    * NLP에서 띄어쓰기, 오타 등이 있어도 정확하게 번역되는 것.
    * ViT는 pre-train dataset이 클수록 robustness함.
    * ViT는 CNN계열과 비교하여 robustness가 좋은 종류가 다름.
* 고도로 작은 패치를 사용하는 ViT는 픽셀 주변을 탐색하는 CNN과 유사한 특징이 있다.
<br><br>


